{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72d8cca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luchinwei/anaconda3/envs/mambastock/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error,r2_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from mamba_test0729 import Mamba, MambaConfig\n",
    "import argparse\n",
    "from datetime import datetime\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from scipy.stats import pearsonr\n",
    "import random\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import spearmanr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe2443c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = '0730_2330/'\n",
    "use_cuda = True\n",
    "seed_num = random.randint(0, 999999)\n",
    "n_steps=10\n",
    "window=15\n",
    "patience = 100\n",
    "epochs = 1000\n",
    "# loss_fnc = F.smooth_l1_loss\n",
    "# loss_fnc = None\n",
    "\n",
    "lr = 0.0005\n",
    "wd = 1e-5\n",
    "hidden = 16\n",
    "layer = 2\n",
    "n_test = 350\n",
    "ts_code = 2330\n",
    "risk_free = 0.017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c57c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_metric(y_test,y_hat):\n",
    "    MSE = mean_squared_error(y_test, y_hat)\n",
    "    RMSE = MSE**0.5\n",
    "    MAE = mean_absolute_error(y_test,y_hat)\n",
    "    R2 = r2_score(y_test,y_hat)\n",
    "    print('%.4f %.4f %.4f %.4f' % (MSE,RMSE,MAE,R2))\n",
    "\n",
    "def set_seed(seed,cuda):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if cuda:\n",
    "        torch.cuda.manual_seed(seed)\n",
    "\n",
    "def dateinf(series, n_test):\n",
    "    lt = len(series)\n",
    "    print('Training start',series[0])\n",
    "    print('Training end',series[lt-n_test-1])\n",
    "    print('Testing start',series[lt-n_test])\n",
    "    print('Testing end',series[lt-1])\n",
    "\n",
    "set_seed(seed_num,use_cuda)\n",
    "\n",
    "\n",
    "class LogCoshLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    def forward(self, pred, target):\n",
    "        loss = torch.log(torch.cosh(pred - target))\n",
    "        return torch.mean(loss)\n",
    "\n",
    "class CharbonnierLoss(nn.Module):\n",
    "    def __init__(self, eps=1e-6):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "    def forward(self, pred, target):\n",
    "        diff = pred - target\n",
    "        loss = torch.sqrt(diff**2 + self.eps**2)\n",
    "        return torch.mean(loss)\n",
    "\n",
    "class QuantileLoss(nn.Module):\n",
    "    def __init__(self, q=0.5):\n",
    "        super().__init__()\n",
    "        self.q = q\n",
    "    def forward(self, pred, target):\n",
    "        e = target - pred\n",
    "        return torch.mean(torch.max(self.q * e, (self.q - 1) * e))\n",
    "\n",
    "\n",
    "\n",
    "class HybridLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.logcosh = LogCoshLoss()\n",
    "    def forward(self, pred, target):\n",
    "        return 0.4 * self.logcosh(pred, target) + 0.6 * F.mse_loss(pred, target)\n",
    "\n",
    "# 結合 RMSE + RIC 方向性損失\n",
    "def make_composite_loss():\n",
    "    def loss_fn(pred, target):\n",
    "        mse = F.mse_loss(pred, target)\n",
    "        ric = spearmanr(pred.detach().cpu().numpy(), target.detach().cpu().numpy())[0]\n",
    "        penalty = torch.tensor(1 - ric**2)  # 強化方向誤差\n",
    "        return mse + 0.5 * penalty\n",
    "    return loss_fn\n",
    "\n",
    "\n",
    "\n",
    "class TopKPairwiseHingeLoss(nn.Module):\n",
    "    def __init__(self, k=10, margin=1.0):\n",
    "        super().__init__()\n",
    "        self.k = k\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, scores, labels):\n",
    "        \"\"\"\n",
    "        scores: [N] tensor of predicted values\n",
    "        labels: [N] tensor of true values (for sorting reference)\n",
    "        \"\"\"\n",
    "        # 取得 top-K 與 bottom-K 的 index\n",
    "        topk_idx = torch.topk(labels, self.k).indices\n",
    "        bottomk_idx = torch.topk(-labels, self.k).indices\n",
    "\n",
    "        # 預測分數差異\n",
    "        score_top = scores[topk_idx]\n",
    "        score_bottom = scores[bottomk_idx]\n",
    "\n",
    "        # 計算 pairwise hinge loss\n",
    "        # 損失 = margin - (top - bottom)，期望 top > bottom\n",
    "        diff = score_top.unsqueeze(1) - score_bottom.unsqueeze(0)\n",
    "        hinge = F.relu(self.margin - diff)\n",
    "\n",
    "        return hinge.mean()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# loss_fnc = LogCoshLoss()\n",
    "# loss_fnc = CharbonnierLoss()\n",
    "# loss_fnc = QuantileLoss()\n",
    "\n",
    "loss_fnc = HybridLoss()\n",
    "# loss_fnc = make_composite_loss()\n",
    "\n",
    "# loss_fnc = TopKPairwiseHingeLoss(k=10, margin=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401750b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_shape(name, tensor):\n",
    "    print(f\"[Shape] {name}: {tuple(tensor.shape)}\")\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim=n_steps, use_pca=False, pca_dim=None, pca_components=None):\n",
    "        super().__init__()\n",
    "        self.use_pca = use_pca\n",
    "\n",
    "        if self.use_pca:\n",
    "            assert pca_dim is not None and pca_components is not None, \"需提供 pca_dim 和 pca_components\"\n",
    "            self.pca_layer = nn.Linear(in_dim, pca_dim, bias=False)\n",
    "            self.pca_layer.weight.data = torch.tensor(pca_components, dtype=torch.float32)\n",
    "            self.pca_layer.weight.requires_grad = False\n",
    "            in_dim = pca_dim  # PCA 之後輸入維度會改變\n",
    "\n",
    "        self.input_proj = nn.Linear(in_dim, hidden)  # 把輸入轉成 hidden 維度\n",
    "\n",
    "        self.config = MambaConfig(d_model=hidden, n_layers=layer, n_steps=out_dim)\n",
    "        self.mamba = Mamba(self.config)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.squeeze(1)                      # → (B, D)\n",
    "\n",
    "        if self.use_pca:\n",
    "            x = self.pca_layer(x)            # → (B, pca_dim)\n",
    "\n",
    "        x = self.input_proj(x)               # → (B, hidden)\n",
    "        x = x.unsqueeze(1)                   # → (B, 1, hidden)\n",
    "\n",
    "        x = self.mamba(x)                    # → (B, n_steps)\n",
    "        \n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "def spearman_metric(y_true, y_pred):\n",
    "    return spearmanr(y_true.cpu().numpy(), y_pred.cpu().numpy())[0]\n",
    "\n",
    "\n",
    "def PredictWithData(trainX, trainy, testX, save_dir, window=window,use_pca=False, pca_dim=None, pca_components=None, val_ratio=0.2, patience=patience, loss_fnc=None):\n",
    "    clf = Net(in_dim=trainX.shape[1], out_dim=n_steps, use_pca=use_pca, pca_dim=pca_dim, pca_components=pca_components)\n",
    "    opt = torch.optim.Adam(clf.parameters(),lr=lr,weight_decay=wd)\n",
    "    \n",
    "    # 分割資料集\n",
    "    val_size = int(len(trainX) * val_ratio)\n",
    "    X_train_raw = trainX[:-val_size]\n",
    "    y_train_raw = trainy[:-val_size]\n",
    "    X_val_raw   = trainX[-val_size:]\n",
    "    y_val_raw   = trainy[-val_size:]\n",
    "\n",
    "    # Horizon 可整除長度\n",
    "    valid_len = len(y_train_raw) - (len(y_train_raw) % n_steps)\n",
    "    val_len   = len(y_val_raw)   - (len(y_val_raw) % n_steps)\n",
    "\n",
    "    # 裁切資料\n",
    "    X_train = X_train_raw[:valid_len]\n",
    "    y_train = y_train_raw[:valid_len]\n",
    "    X_val   = X_val_raw[:val_len]\n",
    "    y_val   = y_val_raw[:val_len]\n",
    "\n",
    "    # 建立 horizon 分組\n",
    "    X_train = X_train.reshape(-1, n_steps, X_train.shape[1])\n",
    "    y_train = y_train.reshape(-1, n_steps)\n",
    "    X_val   = X_val.reshape(-1, n_steps, X_val.shape[1])\n",
    "    y_val   = y_val.reshape(-1, n_steps)\n",
    "\n",
    "    # 取每組 horizon 的最後一個時間步作為模型輸入\n",
    "    xt = torch.from_numpy(X_train[:, -1, :]).float().unsqueeze(1)  # (B, 1, feature_dim)\n",
    "    yt = torch.from_numpy(y_train).float()                         # (B, n_steps)\n",
    "    xv = torch.from_numpy(X_val[:, -1, :]).float().unsqueeze(1)\n",
    "    yv = torch.from_numpy(y_val).float()\n",
    "\n",
    "    # 測試資料不需要 horizon 重組\n",
    "    x_test = torch.from_numpy(testX).float().unsqueeze(1)\n",
    "    \n",
    "    if loss_fnc is None:\n",
    "        loss_fnc = F.mse_loss\n",
    "    \n",
    "    best_r2 = -float('inf')\n",
    "    best_rmse = float('inf')\n",
    "    best_state_dict = None\n",
    "    best_epoch = 0\n",
    "\n",
    "    for e in range(epochs):\n",
    "        clf.train()\n",
    "        pred = clf(xt)\n",
    "        loss = loss_fnc(pred, yt)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        clf.eval()\n",
    "        with torch.no_grad():\n",
    "            val_pred = clf(xv)\n",
    "            val_loss = loss_fnc(val_pred, yv)\n",
    "\n",
    "            val_pred_np = val_pred.cpu().numpy()  # shape: (B, n_steps)\n",
    "            val_true_np = yv.cpu().numpy()\n",
    "\n",
    "            r2_list = [r2_score(val_true_np[:, i], val_pred_np[:, i]) for i in range(val_pred_np.shape[1])]\n",
    "            spearman_list = [spearmanr(val_true_np[:, i], val_pred_np[:, i])[0] for i in range(val_pred_np.shape[1])]\n",
    "\n",
    "            avg_r2 = np.mean(r2_list)\n",
    "            avg_spearman = np.mean(spearman_list)\n",
    "\n",
    "\n",
    "        print(f'Epoch {e:03d} | Avg R²: {avg_r2:.4f} | Avg Spearman: {avg_spearman:.4f}')\n",
    "\n",
    "\n",
    "        if avg_r2 > best_r2:\n",
    "\n",
    "            best_r2 = avg_r2  \n",
    "            best_epoch = e\n",
    "            best_state_dict = clf.state_dict()\n",
    "            best_timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")      \n",
    "        elif e - best_epoch >= patience:\n",
    "            print(f\"Early stopping triggered at epoch {e}\")\n",
    "            break\n",
    "        \n",
    "        # print(f'Epoch {e:03d} | Val RMSE: {RMSE:.4f}')\n",
    "\n",
    "        # if RMSE < best_rmse:\n",
    "        #     best_rmse = RMSE\n",
    "        #     best_epoch = e\n",
    "        #     best_state_dict = clf.state_dict()\n",
    "        #     best_timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")      \n",
    "        # elif e - best_epoch >= patience:\n",
    "        #     print(f\"Early stopping triggered at epoch {e}\")\n",
    "        #     break\n",
    "\n",
    "    best_model_path = f\"{save_dir}model_{best_timestamp}.pth\"\n",
    "    torch.save(best_state_dict, best_model_path)\n",
    "    print(f\"Best model saved to: {best_model_path}\")\n",
    "    \n",
    "    \n",
    "    val_pred_np = val_pred.cpu().numpy() if use_cuda else val_pred.numpy()\n",
    "    val_true_np = yv.cpu().numpy()\n",
    "\n",
    "    mse_list = [mean_squared_error(val_true_np[:, i], val_pred_np[:, i]) for i in range(n_steps)]\n",
    "    rmse_list = [mse ** 0.5 for mse in mse_list]\n",
    "    mae_list = [mean_absolute_error(val_true_np[:, i], val_pred_np[:, i]) for i in range(n_steps)]\n",
    "    r2_list = [r2_score(val_true_np[:, i], val_pred_np[:, i]) for i in range(n_steps)]\n",
    "    spearman_list = [spearmanr(val_true_np[:, i], val_pred_np[:, i])[0] for i in range(n_steps)]\n",
    "\n",
    "    avg_rmse = np.mean(rmse_list)\n",
    "    avg_mae = np.mean(mae_list)\n",
    "    avg_r2 = np.mean(r2_list)\n",
    "    avg_spearman = np.mean(spearman_list)\n",
    "\n",
    "\n",
    "    # 儲存評估指標\n",
    "    # 儲存評估指標\n",
    "    # log_path = f\"{save_dir}/evaluation_log.txt\"\n",
    "    # with open(log_path, 'a') as f:\n",
    "    #     f.write(f\"Model: model_{best_timestamp}.pth\\n\")\n",
    "    #     f.write(f\"  MSE: {MSE:.4f} | RMSE: {RMSE:.4f} | MAE: {MAE:.4f} | R²: {R2:.4f}\\n\")\n",
    "    #     f.write(\"-\" * 60 + \"\\n\")\n",
    "    log_path = f\"{save_dir}/evaluation_log.txt\"\n",
    "    with open(log_path, 'a') as f:\n",
    "        f.write(f\"Model: model_{best_timestamp}.pth\\n\")\n",
    "        f.write(f\"  Avg RMSE: {avg_rmse:.4f} | Avg MAE: {avg_mae:.4f} | Avg R²: {avg_r2:.4f} | Avg Spearman: {avg_spearman:.4f}\\n\")\n",
    "        f.write(\"-\" * 60 + \"\\n\")\n",
    "\n",
    "    \n",
    "    clf.load_state_dict(best_state_dict)\n",
    "    clf.eval()\n",
    "    mat = clf(x_test)\n",
    "    if use_cuda: mat = mat.cpu()\n",
    "    yhat = mat.detach().cpu().numpy() \n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6dd93eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PowerTransformer\n",
    "data = pd.read_csv(str(ts_code)+\"_value\"+'.csv')\n",
    "data['trade_date'] = pd.to_datetime(data['trade_date'], format='%Y/%m/%d')\n",
    "\n",
    "# 加入星期幾（0=星期一, 6=星期日）\n",
    "data['day_of_week'] = data['trade_date'].dt.dayofweek\n",
    "\n",
    "# 加入月份（1～12）\n",
    "data['month'] = data['trade_date'].dt.month\n",
    "\n",
    "\n",
    "\n",
    "# 拆離 label 欄位\n",
    "close = data.pop('close_TW').values\n",
    "ratechg = data['close_TW_roc'].values *100\n",
    "\n",
    "\n",
    "pt = PowerTransformer(method='yeo-johnson')\n",
    "ratechg = pt.fit_transform(ratechg.reshape(-1, 1))\n",
    "\n",
    "\n",
    "data.drop(columns=['close_TW_roc'], inplace=True)\n",
    "\n",
    "# 擷取有效特徵欄位區段\n",
    "dat = data.iloc[:, 4:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e6e65a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2520, 61)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6d74952",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PowerTransformer\n",
    "data = pd.read_csv(str(ts_code)+\"_value\"+'.csv')\n",
    "data['trade_date'] = pd.to_datetime(data['trade_date'], format='%Y/%m/%d')\n",
    "\n",
    "# 加入星期幾（0=星期一, 6=星期日）\n",
    "data['day_of_week'] = data['trade_date'].dt.dayofweek\n",
    "\n",
    "# 加入月份（1～12）\n",
    "data['month'] = data['trade_date'].dt.month\n",
    "\n",
    "\n",
    "\n",
    "# 拆離 label 欄位\n",
    "close = data.pop('close_TW').values\n",
    "ratechg = data['close_TW_roc'].values *100\n",
    "\n",
    "\n",
    "pt = PowerTransformer(method='yeo-johnson')\n",
    "ratechg = pt.fit_transform(ratechg.reshape(-1, 1))\n",
    "\n",
    "\n",
    "data.drop(columns=['close_TW_roc'], inplace=True)\n",
    "\n",
    "# 擷取有效特徵欄位區段\n",
    "dat = data.iloc[:, 4:].values\n",
    "\n",
    "num_samples = dat.shape[0]\n",
    "\n",
    "# 產生 horizon indicator（重複每個 horizon 一次）\n",
    "horizon_ids = np.tile(np.arange(n_steps), num_samples).reshape(num_samples, n_steps)\n",
    "\n",
    "# 將其合併成新特徵\n",
    "dat = np.repeat(dat[:, np.newaxis, :], n_steps, axis=1)  # shape: [samples, horizon, features]\n",
    "dat = np.concatenate([dat, horizon_ids[..., np.newaxis]], axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c28e932f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2520, 10, 62)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0248585d",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_pca = False\n",
    "pca_dim = 25\n",
    "\n",
    "\n",
    "if use_pca:\n",
    "    pca = PCA(n_components=pca_dim)\n",
    "    pca.fit(dat)\n",
    "\n",
    "    pca_components = pca.components_[:pca_dim]\n",
    "    dat_pca = dat @ pca_components.T\n",
    "else:\n",
    "    dat_pca = dat \n",
    "    \n",
    "trainX, testX = dat_pca[:-n_test], dat_pca[-n_test:]\n",
    "trainy = ratechg[:-n_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0007c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886654e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777f9739",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6e5244",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ratio=0.2\n",
    "val_size = int(len(trainX) * val_ratio)\n",
    "X_train_raw = trainX[:-val_size]\n",
    "y_train_raw = trainy[:-val_size]\n",
    "X_val_raw   = trainX[-val_size:]\n",
    "y_val_raw   = trainy[-val_size:]\n",
    "\n",
    "# Horizon 可整除長度\n",
    "valid_len = len(y_train_raw) - (len(y_train_raw) % n_steps)\n",
    "val_len   = len(y_val_raw)   - (len(y_val_raw) % n_steps)\n",
    "\n",
    "# 裁切資料\n",
    "X_train = X_train_raw[:valid_len]\n",
    "y_train = y_train_raw[:valid_len]\n",
    "X_val   = X_val_raw[:val_len]\n",
    "y_val   = y_val_raw[:val_len]\n",
    "\n",
    "# 建立 horizon 分組\n",
    "X_train = X_train.reshape(-1, n_steps, X_train.shape[1])\n",
    "y_train = y_train.reshape(-1, n_steps)\n",
    "X_val   = X_val.reshape(-1, n_steps, X_val.shape[1])\n",
    "y_val   = y_val.reshape(-1, n_steps)\n",
    "\n",
    "# 取每組 horizon 的最後一個時間步作為模型輸入\n",
    "xt = torch.from_numpy(X_train[:, -1, :]).float().unsqueeze(1)  # (B, 1, feature_dim)\n",
    "yt = torch.from_numpy(y_train).float()                         # (B, n_steps)\n",
    "xv = torch.from_numpy(X_val[:, -1, :]).float().unsqueeze(1)\n",
    "yv = torch.from_numpy(y_val).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a03d896e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for i in range(window + n_steps, len(data)):\n",
    "    X.append(dat[i - window - n_steps : i - n_steps])  # [15, features]\n",
    "    y.append(ratechg[i - n_steps : i])                 # [10,]\n",
    "\n",
    "X = np.array(X)  # shape: [samples, window, features]\n",
    "y = np.array(y)  # shape: [samples, n_steps]\n",
    "\n",
    "val_ratio = 0.2\n",
    "val_size = int(len(X) * val_ratio)\n",
    "\n",
    "X_train = X[:-val_size]\n",
    "y_train = y[:-val_size]\n",
    "X_val   = X[-val_size:]\n",
    "y_val   = y[-val_size:]\n",
    "\n",
    "# 轉換成 tensor\n",
    "xt = torch.from_numpy(X_train).float()     # [B, window, features]\n",
    "yt = torch.from_numpy(y_train).float()     # [B, n_steps]\n",
    "xv = torch.from_numpy(X_val).float()\n",
    "yv = torch.from_numpy(y_val).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7659401",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'testX' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_16783/60859403.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# shape: [1, window, features]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'testX' is not defined"
     ]
    }
   ],
   "source": [
    "x_test = torch.from_numpy(testX[-window:]).float().unsqueeze(0)  # shape: [1, window, features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1dbf1ad9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1996, 15, 10, 62])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d5a4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "yt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50245e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ff26da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PowerTransformer\n",
    "data = pd.read_csv(str(ts_code)+\"_value\"+'.csv')\n",
    "data['trade_date'] = pd.to_datetime(data['trade_date'], format='%Y/%m/%d')\n",
    "\n",
    "# 加入星期幾（0=星期一, 6=星期日）\n",
    "data['day_of_week'] = data['trade_date'].dt.dayofweek\n",
    "\n",
    "# 加入月份（1～12）\n",
    "data['month'] = data['trade_date'].dt.month\n",
    "\n",
    "\n",
    "\n",
    "# 拆離 label 欄位\n",
    "close = data.pop('close_TW').values\n",
    "ratechg = data['close_TW_roc'].values *100\n",
    "\n",
    "\n",
    "pt = PowerTransformer(method='yeo-johnson')\n",
    "ratechg = pt.fit_transform(ratechg.reshape(-1, 1))\n",
    "\n",
    "\n",
    "data.drop(columns=['close_TW_roc'], inplace=True)\n",
    "\n",
    "# 擷取有效特徵欄位區段\n",
    "dat = data.iloc[:, 4:].values\n",
    "\n",
    "num_samples = dat.shape[0]\n",
    "\n",
    "# 產生 horizon indicator（重複每個 horizon 一次）\n",
    "horizon_ids = np.tile(np.arange(n_steps), num_samples).reshape(num_samples, n_steps)\n",
    "\n",
    "# 將其合併成新特徵\n",
    "dat = np.repeat(dat[:, np.newaxis, :], n_steps, axis=1)  # shape: [samples, horizon, features]\n",
    "dat = np.concatenate([dat, horizon_ids[..., np.newaxis]], axis=2)\n",
    "\n",
    "use_pca = False\n",
    "pca_dim = 25\n",
    "\n",
    "\n",
    "if use_pca:\n",
    "    pca = PCA(n_components=pca_dim)\n",
    "    pca.fit(dat)\n",
    "\n",
    "    pca_components = pca.components_[:pca_dim]\n",
    "    dat_pca = dat @ pca_components.T\n",
    "else:\n",
    "    dat_pca = dat \n",
    "    \n",
    "trainX, testX = dat_pca[:-n_test], dat_pca[-n_test:]\n",
    "trainy = ratechg[:-n_test]\n",
    "# trainy = pd.Series(trainy).ewm(span=5).mean().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bd03ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "predictions = PredictWithData(trainX, trainy, testX, save_dir, loss_fnc=loss_fnc)\n",
    "time = data['trade_date'][-n_test:]\n",
    "data1 = close[-n_test:]\n",
    "finalpredicted_stock_price = []\n",
    "pred = close[-n_test-1]\n",
    "for i in range(n_test):\n",
    "    pred = close[-n_test-1+i]*(1+predictions[i])\n",
    "    finalpredicted_stock_price.append(pred)\n",
    "    \n",
    "    \n",
    "dateinf(data['trade_date'],n_test)\n",
    "print('MSE RMSE MAE R2')\n",
    "evaluation_metric(data1, finalpredicted_stock_price)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(time, data1, label='Stock Price')\n",
    "plt.plot(time, finalpredicted_stock_price, label='Predicted Stock Price')\n",
    "plt.title('Stock Price Prediction')\n",
    "plt.xlabel('Time', fontsize=12, verticalalignment='top')\n",
    "plt.ylabel('Close', fontsize=14, horizontalalignment='center')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baef8b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = torch.from_numpy(testX).float().unsqueeze(1)\n",
    "\n",
    "clf = Net(in_dim=trainX.shape[1], out_dim=n_steps, use_pca=use_pca)\n",
    "clf.load_state_dict(torch.load(\"0730_2330/model_20250730_092957.pth\"))\n",
    "clf.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = clf(x_test)\n",
    "testy = ratechg[-n_test:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ee3d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "testy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8caa62",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45bc26ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(predictions.shape[1]):\n",
    "    plt.scatter(range(len(predictions)), predictions[:, i], label=f'horizon {i+1}')\n",
    "plt.legend()\n",
    "plt.title(\"Prediction over Time for Different Horizons\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d324d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "testy = ratechg[-n_test:]\n",
    "\n",
    "def create_horizon_labels(ratechg_segment, horizon=n_steps):\n",
    "    labels = []\n",
    "    for i in range(len(ratechg_segment) - horizon + 1):\n",
    "        labels.append(ratechg_segment[i:i+horizon])\n",
    "    return np.array(labels)\n",
    "\n",
    "testy = create_horizon_labels(ratechg[-n_test:], horizon=n_steps)\n",
    "for i in range(testy.shape[1]):\n",
    "    print(f\"Horizon {i+1} 平均報酬率: {testy[:, i].mean():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704fbe0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_raw = predictions  # 暫存原始輸出\n",
    "print(\"Shape before stack:\", pred_raw.shape)\n",
    "\n",
    "predictions = np.stack([\n",
    "    pt.inverse_transform(pred_raw[:, i].reshape(-1, 1)).flatten()\n",
    "    for i in range(pred_raw.shape[1])\n",
    "], axis=1)\n",
    "\n",
    "predictions = predictions / 100\n",
    "testy = pt.inverse_transform(testy.reshape(-1, 1))\n",
    "testy = testy.flatten() / 100 \n",
    "print(predictions.shape)\n",
    "print(testy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e0b8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_horizon_labels(ratechg_segment, horizon=n_steps):\n",
    "    labels = []\n",
    "    for i in range(len(ratechg_segment) - horizon + 1):\n",
    "        labels.append(ratechg_segment[i:i+horizon])\n",
    "    return np.array(labels)\n",
    "\n",
    "# 重新生成 testy 對應未來三天的報酬率\n",
    "testy = create_horizon_labels(ratechg[-n_test:], horizon=n_steps)\n",
    "print(testy.shape)  # 應該是 (350, 3) 或 (348, 3)，看長度而定\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461e0238",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_pred = predictions\n",
    "y_pred = y_pred[:341]\n",
    "\n",
    "print(\"testy:\", testy.shape)\n",
    "print(\"y_pred:\", y_pred.shape)\n",
    "\n",
    "\n",
    "for i in range(n_steps):\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.scatter(testy[:, i], y_pred[:, i], alpha=0.6, color='steelblue', edgecolor='k')\n",
    "    min_val = min(testy[:, i].min(), y_pred[:, i].min())\n",
    "    max_val = max(testy[:, i].max(), y_pred[:, i].max())\n",
    "    plt.plot([min_val, max_val], [min_val, max_val], 'r--', label='y = x')\n",
    "    plt.xlabel(f\"True Return (t+{i+1})\")\n",
    "    plt.ylabel(f\"Predicted Return (t+{i+1})\")\n",
    "    plt.title(f\"Horizon t+{i+1} Residual Scatter\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d2055a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.histplot(y_pred.flatten(), bins=100, kde=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7249b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = y_pred.flatten() - testy.flatten()\n",
    "sns.histplot(residuals, bins=100, kde=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288ec267",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mambastock",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
